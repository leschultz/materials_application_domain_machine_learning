{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Install dependencies"
      ],
      "metadata": {
        "id": "N9YonbivJF1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkbvapstI0dv"
      },
      "outputs": [],
      "source": [
        "!pip install madml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages for run"
      ],
      "metadata": {
        "id": "p8teOKc3SGib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from madml.ml.splitters import BootstrappedLeaveClusterOut\n",
        "from madml.models.space import distance_model\n",
        "from madml.models.combine import domain_model\n",
        "from madml.models.uq import calibration_model\n",
        "from madml.ml.assessment import nested_cv\n",
        "from madml import datasets"
      ],
      "metadata": {
        "id": "JbLKBwbMSJ5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data\n",
        "There are a set of datasets available. You can load any of them with the name given by the following command."
      ],
      "metadata": {
        "id": "pmSXxALOSzWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.list_data()"
      ],
      "metadata": {
        "id": "wkAU4MlJTI0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any of the supported data can be loaded in a standard manner. You are capable of loading your own data instead of any of the supported datasest if needed."
      ],
      "metadata": {
        "id": "zOve0Ix6TWtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    data = datasets.load('diffusion')\n",
        "    X = data['data']\n",
        "    y = data['target']\n",
        "    g = data['class_name']"
      ],
      "metadata": {
        "id": "3IAIaEYAS5FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model\n",
        "We define three model types: uncertanty quantification, distance, and regression model. If we want uncertainty quantification, the regression model must be an ensmble model (e.g. random forest, bagged LASSO, et cetera)."
      ],
      "metadata": {
        "id": "-TN0y0eITtpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with a distance model."
      ],
      "metadata": {
        "id": "jIhXifFXUIIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_model = distance_model(dist='kde')"
      ],
      "metadata": {
        "id": "xh0Loz7HUB1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we add a polynomial uncertaty quantifiction model. The number of arguments for te argument params defines the degree of the polynomial, and their values are the inital guesses to the optimizer."
      ],
      "metadata": {
        "id": "_Oa1QvL2UTp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uq_model = calibration_model(params=[0.0, 1.0])"
      ],
      "metadata": {
        "id": "NAS-I9SHUSak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define the regression model. The regression model must be a gridserach object with a pipeline. The example here does not iterate over folds for hyperparamter optimization, but it can be modified to do so."
      ],
      "metadata": {
        "id": "auaYZY1LUjuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML\n",
        "scale = StandardScaler()\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# The grid for grid search\n",
        "grid = {}\n",
        "grid['model__n_estimators'] = [100]\n",
        "\n",
        "# The machine learning pipeline\n",
        "pipe = Pipeline(steps=[\n",
        "                        ('scaler', scale),\n",
        "                        ('model', model),\n",
        "                        ])\n",
        "\n",
        "# The gridsearch model\n",
        "gs_model = GridSearchCV(\n",
        "                        pipe,\n",
        "                        grid,\n",
        "                        cv=((slice(None), slice(None)),),  # No splits\n",
        "                        )"
      ],
      "metadata": {
        "id": "8OB0Uv4fU6Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the splits\n",
        "Here comes the fun part. The performance of a model on a test set depends on many things. We want to guard against using predictions on data that are sampled dissimilarly to the data used for training. First, we build splits where test data are sampled similarly to training data. We give these splits the special name of \"calibration\" so that we only use this kind of splitter for our uncertainty quantification model."
      ],
      "metadata": {
        "id": "F4dq9zc1VMvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_repeats = 2  # The number of time to repeat splits\n",
        "splits = [('calibration', RepeatedKFold(n_repeats=n_repeats))]"
      ],
      "metadata": {
        "id": "VKWSvgJcVP-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How we need to tell the model what data are dissimilar. We use come pre-clustering and split data accordingly. Here, we do 2 and 3 cluster and use agglomerative clustering."
      ],
      "metadata": {
        "id": "qhC45B31WLeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [2, 3]:\n",
        "\n",
        "    # Cluster Splits\n",
        "    top_split = BootstrappedLeaveClusterOut(\n",
        "                                            AgglomerativeClustering,\n",
        "                                            n_repeats=n_repeats,\n",
        "                                            n_clusters=i\n",
        "                                            )\n",
        "\n",
        "    splits.append(('agglo_{}'.format(i), top_split))"
      ],
      "metadata": {
        "id": "zQmagWiqWB75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessing and Fitting the Model\n",
        "Now, we assess the model through cross valication and then fit a final model on all data that can be used by a researcher. The assessment of the model is saved in a directory of the user's choice."
      ],
      "metadata": {
        "id": "HCL2WngJWphB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = domain_model(gs_model, ds_model, uq_model, splits)\n",
        "cv = nested_cv(X, y, g, model, splits, save='./run')\n",
        "_, model = cv.assess()"
      ],
      "metadata": {
        "id": "5oXHWVwfXOK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of Model Use\n",
        "Our assessment returns a model. We can also use dill to load the saved model in the ./run/model/model.dill. Here, we predict on the features used to build the model."
      ],
      "metadata": {
        "id": "twibWAl5Xcrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = model.predict(X)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "vTIBKQhJXgT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}